{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model ensemble\n",
    "\n",
    "The easiest way to pool the predictions of a set of classifiers (to ensemble the classifiers) is to average their predictions at inference time. \n",
    "\n",
    "More sofisticated way to ensemble classifiers is to do a weighted average, where the weights are learned on the validation data. Typically, the better classifiers are given a higher weight, and the worse classifiers are given a lower weight. To search for a good set of ensembling weights, we used SLSQP optimization algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import src.model_ensemble as ensemble\n",
    "\n",
    "from src.data.loaders import load_and_clean_data\n",
    "from src.definitions import ROOT_PATH\n",
    "from src.definitions import TEST_PATH\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "ROWS = 10000\n",
    "\n",
    "models = ensemble.init_models()\n",
    "\n",
    "tokenizer_path = os.path.join(\n",
    "    ROOT_PATH, \"models/{}\".format(\"tokenizer.pkl\"))\n",
    "\n",
    "with open(tokenizer_path, \"rb\") as file:\n",
    "    tokenizer = pickle.load(file)\n",
    "\n",
    "# Load validation reviews\n",
    "val_samples, val_labels = load_and_clean_data(path=TEST_PATH, nrows=ROWS)\n",
    "sequences = tokenizer.texts_to_sequences(val_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: convnet_keras\n",
      "10000/10000 [==============================] - 2s 198us/step\n",
      "Accuracy: 0.9466\n",
      "\n",
      "Evaluating: convnet_lstm\n",
      "10000/10000 [==============================] - 6s 562us/step\n",
      "Accuracy: 0.9506\n",
      "\n",
      "Evaluating: lstm\n",
      "10000/10000 [==============================] - 19s 2ms/step\n",
      "Accuracy: 0.9531\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = ensemble.models_prediction(sequences, val_labels, models)\n",
    "accuracies = np.array([np.mean(np.round(pred) == val_labels) for pred in predictions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCALE_FACTOR = -100.0\n",
    "\n",
    "def objective_function(x):\n",
    "    ensemble_predictions = ensemble.ensemble_prediction(predictions, weights=x)\n",
    "    ensemble_accuracy = np.mean(ensemble_predictions == val_labels)\n",
    "    \n",
    "    value = SCALE_FACTOR * ensemble_accuracy\n",
    "    grads = -accuracies\n",
    "    return value, grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: -95.6\n",
      "            Iterations: 2\n",
      "            Function evaluations: 13\n",
      "            Gradient evaluations: 2\n"
     ]
    }
   ],
   "source": [
    "x0 = np.zeros((len(predictions), 1)) / len(predictions)\n",
    "bounds = [(0, 1)] * len(predictions)\n",
    "constraints = [{\n",
    "    'type': 'eq',\n",
    "    'fun': lambda x: 1.0 - np.sum(x) \n",
    "}]\n",
    "\n",
    "result = minimize(objective_function, \n",
    "                  x0, \n",
    "                  jac=True, \n",
    "                  method='SLSQP', \n",
    "                  bounds=bounds,\n",
    "                  constraints=constraints,\n",
    "                  tol=1e-7, \n",
    "                  options={'disp': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.32983265 0.33383343 0.33633392]\n",
      "True\n",
      "Optimization terminated successfully.\n"
     ]
    }
   ],
   "source": [
    "print(result.x)\n",
    "print(result.success)\n",
    "print(result.message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: convnet_keras\n",
      "398960/398960 [==============================] - 47s 118us/step\n",
      "Accuracy: 0.9484\n",
      "\n",
      "Evaluating: convnet_lstm\n",
      "398960/398960 [==============================] - 204s 510us/step\n",
      "Accuracy: 0.9538\n",
      "\n",
      "Evaluating: lstm\n",
      "398960/398960 [==============================] - 766s 2ms/step\n",
      "Accuracy: 0.9555\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_samples, test_labels = load_and_clean_data(path=TEST_PATH)\n",
    "sequences = tokenizer.texts_to_sequences(test_samples)\n",
    "model_predictions = ensemble.models_prediction(sequences, test_labels, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ensemble accuracy: 0.95841\n",
      "Weighted mean ensemble accuracy: 0.95841\n"
     ]
    }
   ],
   "source": [
    "ensemble_prediction = ensemble.ensemble_prediction(model_predictions)\n",
    "mean_ensemble_accuracy = np.mean(ensemble_prediction == test_labels)\n",
    "print(\"Mean ensemble accuracy: {:.5f}\".format(mean_ensemble_accuracy))\n",
    "\n",
    "ensemble_prediction = ensemble.ensemble_prediction(model_predictions, weights=result.x)\n",
    "weighted_ensemble_accuracy = np.mean(ensemble_prediction == test_labels)\n",
    "print(\"Weighted mean ensemble accuracy: {:.5f}\".format(weighted_ensemble_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
